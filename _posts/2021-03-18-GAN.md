---
layout: post
title:  "GAN"
summary: "Generative Adversarial Network Summary"
author: taehun
date: '2021-03-18 11:48:00 +0900'
category: DeepLearning
toc: true
toc_sticky: true
toc_label: "My Table of Contents"
toc_icon: "cog"
thumbnail: null
keywords: GAN, Discriminator, Generator
permalink: /4
use_math: true
mathjax: true
---

> `Generative Adversarial Network`에 대한 정리. update중 3/18~

#### Index
---

- [GAN](#gan)
- [GAN Training](#gan-training)<br>
- [Reference](#reference) <br>


#### GAN
---

<h4><span style="color:red">G</span>enerative <span style="color:red">A</span>dversarial <span style="color:red">N</span>etwork</h4><br>

Q. What if we give up on explicitly modeling density and just want ability to sample?

- Main Tasks : 이미지/음성 등의 complex/high dimension 데이터에 대한 training distribution으로붙 sampling 하는 것.

- Solution : Two step approach

  1. Random noise처럼 sampling하기 아주 쉬운 simple distribution으로부터 sampling.<br>
  (cf. VAE의 경우에는, training set에 의해서 쉬운 prior를 가정하고, 특정한 latent 위치로 가는 z에 대해 decoding하는 아이디어이지만, GAN의 경우 random하게 sampling)
  2. 강력한 Neural Net을 사용하여 Training distribution에서 발생하는 noise의 transformation을 학습하는 것(distribution이 만들어내는 noise가 transformation을 통해 원하는 형태가 될 수 있도록.)<br><br>

- p<sub>&#952;</sub>(x) 즉, (explicit density function)를 이용하는 것이 아님.  
  - Noise를 generator network에 넣어서 sample을 만드는 것.
  - 이 때, game-theoretic approach를 이용.
  - 2-player game을 통해 training distribution으로부터 데이터를 generate하도록 학습한다.<br>

- Generator Network
  - Discriminator가 진짜 data라고 착각하도록 가짜 데이터를 만들어내느 것이 목적
  - directly produces samples x̃ = G(z;&#952;<sub>g</sub>) = G<sub>&#952;<sub>g</sub></sub>(z)<br>

- Adversary : Discriminator network
  - training data로부터 sampling한 sample들과 generator로부터 만들어낸 samples를 구별해내느 것이 목적
  - D(x;&#952;<sub>d</sub>) = D<sub>&#952;<sub>d</sub></sub>(x) (emits probability value<br>

#### GAN Training
---

- Discriminator 관점 : **maximize** J<sub>D</sub> wrt &#952;<sub>d</sub><br>
  - J<sub>D</sub> = **E<sub>x ~ p<sub>data</sub></sub>logD<sub>&#952;<sub>d</sub></sub>(x)** + **E<sub>z ~ p(z)</sub>log(1-D<sub>&#952;<sub>d</sub></sub>(G<sub>&#952;<sub>g</sub></sub>(z)))**<br>
    (z : noise, 대부분의 경우 from Gaussian noise, G<sub>&#952;<sub>g</sub></sub>(z) : fake data x̃)<br>
    
    1) 첫번째 항은 data로부터 sampling한 sample x를 대상으로, Discriminator D 입장에서 real data x가 real data라고 판단할 확률이 maximize 될 수 있도록 parameter &#952;<sub>d</sub>를 학습한다.<br><br>
    2) 두번째 항은 Generator가 noise z를 이용해서 만들어낸 fake data G(z)를 바탕으로 Discriminator 입장에서 fake data G(z)가 진짜라고 판단할 확률이 0이 되도록 즉, 가짜 데이터라고 판단하도록 D(G(z))값을 minimize 하는 것 즉, 1-D(G(z)) 값을 maximize 하도록 &#952;<sub>d</sub>를 학습한다.<br><br>
    - 즉, 첫번째 항과 두번째 항 모두 값이 **maximize 될 수 있도록 &#952;<sub>d</sub>를 학습한다.**<br>
    
- Generator 관점 : **minimize** J<sub>G</sub> wrt &#952;<sub>g</sub>
  - J<sub>G</sub> = E<sub>z ~ p(z)</sub>log(1-D<sub>&#952;<sub>d</sub></sub>(G<sub>&#952;<sub>g</sub></sub>(z)))
    1) Generator는 Discriminator가 fake data x̃를 real data로 판단하도록 parameter &#952;<sub>g</sub>를 학습한다.<br>

- Minmax game
  - Generator/Discriminator를 함께 minmax game을 통해 학습시키는 것.<br>
  - minmax objective
    : <span style="color:red">min</span><span style="color:blue">max</span>[E<sub>x ~ p<sub>data</sub></sub>log<span style="color:blue">D<sub>&#952;<sub>d</sub></sub></span>(x) + E<sub>z ~ p(z)</sub>log(1-<span style="color:blue">D<sub>&#952;<sub>d</sub></sub></span>(<span style="color:red">G<sub>&#952;<sub>g</sub></sub></span>(z)))]<br>
    &emsp;&emsp;&nbsp;<small><span style="color:red">&#952;<sub>g</sub></span></small>&nbsp;&nbsp;&nbsp;&nbsp;<small><span style="color:blue">&#952;<sub>d</sub></span></small>

$$ x_k $$

\\ x_k \\


<br>

#### Reference
---

<h4>- Reference</h4><br>

- 서울대학교 전기전자공학부 윤성로 교수님 딥러닝 강의 : <https://www.youtube.com/channel/UCEkAV8kTc87PogbVLq-nd6A>
